# for Scan3R data
data :
  name            : Scan3R
  root_dir        : '' # to be read in code from env varia  
  rescan: True
  temporal: True
  resplit: True
  img:
    img_step: 1
    w: 960
    h: 540
  img_encoding:
    # image patch config
    resize_w: 1024 # resize image for backbone GCVit
    resize_h: 576
    img_rotate: True # rotate w,h for backbone GCVit
    patch_w: 16 # number of patchs in width
    patch_h: 9
    record_feature: False # record feature or raw image
    use_feature: True # use feature or raw image
    preload_feature: True
    feature_dir: "Features2D/DinoV2_16_9_scan" # relative to data_root_dir/files
  cross_scene:
    use_cross_scene: True
    num_scenes: 9 # number of scenes 
    num_negative_samples: -1 # number of negative samples 
  scene_graph:
    obj_img_patch: "Features3D/obj_dinov2_top10_l3"
    obj_topk: 10
    obj_patch_num: 100

# for scene graph embedding
sgaligner:
  use_pretrained : False
  pretrained: ""
  label_file_name : labels.instances.annotated.v2.ply
  pred_subfix     : inseg.ply

  seed: 42
  model_name    : 'sgaligner'
  modules       : ['point', 'gat', 'rel', 'attr', 'img_patch']
  # modules       : ['point', 'gat', 'rel', 'attr']
  use_predicted : False
  registration  : False
  scan_type     : 'scan'
  img_transformer: False
  use_pos_enc: True
  
  preprocess :
    pc_resolutions      : [64, 128, 256, 512]
    subscenes_per_scene : 1
    filter_segment_size : 512
    min_obj_points      : 50
    anchor_type_name    : '' 

  model :
    rel_dim             : 41
    attr_dim            : 164
    img_patch_feat_dim  : 1536
    img_emb_dim: 256
    alignment_thresh    : 0.4
    multi_view_aggregator: 'transformer'
  train :
    pc_res: 512

  val :
    pc_res: 512
    overlap_low         : 0.0
    overlap_high        : 0.0
    data_mode: orig

# our model
model_name    : 'ObjectPatchAligner'

# for 2D-3D object match
model:
  # backbone, currently not used here because we use pre-computed features for speed up
  backbone: 
    # to be read in code from env varia, relative to VLSG_SPACE
    use_pretrained: False
    cfg_file: "./src/models/GCVit/configs/gcvit/cascade_mask_rcnn_gcvit_tiny_3x_coco.py"
    pretrained: "./checkpoint/GCVit/gcvit_1k_tiny.pth.tar"
    num_reduce: 0 # should be log2(resize_w/(32*patch_w))
    backbone_dim: 1536 # dim of DinoV2 features
  # patch feature encoder
  patch:
    hidden_dims: [512] # last is the out dim
    encoder_dim: 400
    gcn_layers: 2
  # 3D obj embedding encoder
  obj:
    embedding_dim: 656 # fixed
    embedding_hidden_dims: [512, 512]
    encoder_dim: 400
  other:
    drop: 0.1

# implemetation
output_dir: "" # to be read in code from env varia
mode: "train"
# for training
train:
  batch_size: 16
  num_workers: 16
  use_pretrained: False
  log_steps: 20
  snapshot_steps: 1
  optim:
    lr: 0.0011
    scheduler: "step"
    lr_decay: 0.97
    lr_decay_steps: 1
    lr_min: 0.0005
    T_max: 1000
    T_mult: 1
    weight_decay: 0.000001
    max_epoch: 10500
    free_backbone_epoch: 10500 # freeze backbone until certain epochs
    free_sgaligner_epoch: -1 # freeze sgaligner until certain epochs
    grad_acc_steps: 1
  loss:
    use_temporal: True
    loss_type: "ICLLossBothSidesSumOutLog"
    alpha: 0.5
    temperature: 0.1
    margin: 0.5
  data_aug:
    use_aug: True
    img:
      rotation: 60.0
      horizontal_flip: 0.5
      vertical_flip: 0.5
      color: 0.3
    use_aug_3D: True
    pcs:
      granularity: [0.05, 0.2, 0.4]
      magnitude: [0.2, 0.4, 0.4]
    
  # for vis
  use_vis: False
  vis_epoch_steps: 100
# for validation
val:
  batch_size: 16
  num_workers: 16
  pretrained: "./"
  room_retrieval:
    epsilon_th: 0.8
    method_name: ""
other:
  use_resume: False
  # to be read in code from env varia, relative to VLSG_TRAINING_OUT_DIR
  resume_folder: "" # to be read in code from env varia
  resume: "./snapshots/epoch-8.pth.tar" 
# others
seed: 42